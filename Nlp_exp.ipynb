{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhbvvMIN5rT7BrqLO0r21w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/11239m006/Natural_Language_Processing/blob/main/Nlp_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization**\n",
        "\n"
      ],
      "metadata": {
        "id": "5DFBHPfwcxDf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLLkk8gdawRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0b094c-b406-4ccb-d6a7-fe028ad19d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'Natural', 'Language', 'Processing', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # <-- required in the latest NLTK\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"I love Natural Language Processing.\"\n",
        "print(word_tokenize(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stemming**"
      ],
      "metadata": {
        "id": "6AJSeqk1fa7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "words = [\"playing\", \"played\", \"plays\"]\n",
        "print([ps.stem(w) for w in words])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH5dqNWZcGo7",
        "outputId": "2fcd2b14-75c9-4bf8-8c00-434bd21d61c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['play', 'play', 'play']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lemmatization**"
      ],
      "metadata": {
        "id": "t8cscfSNftnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lm = WordNetLemmatizer()\n",
        "print(lm.lemmatize(\"running\", pos='v'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IYtbqQfcceQ",
        "outputId": "598e0dec-c9f9-4cff-a8ed-4bd72ce2caa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Morphology (Prefix/Suffix Split Example)**"
      ],
      "metadata": {
        "id": "hg9_iPs2f1kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"unkindness\"\n",
        "prefix, root, suffix = word[:2], word[2:-4], word[-4:]\n",
        "print(prefix, root, suffix)   # un + kind + ness\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5GE3mdAcnN6",
        "outputId": "ff1161f3-2a05-4af3-de6a-06ea38a0c61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "un kind ness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normalization**\n"
      ],
      "metadata": {
        "id": "Jiwkoe6lijN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello!!! NLP, is FUN.\"\n",
        "text = text.lower()\n",
        "print(re.sub(r'[^a-zA-Z\\s]', '', text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIpb5wZ7cq1X",
        "outputId": "ef2ff1d9-fc40-49da-8ec0-3136bb2557ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello nlp is fun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **N-Gram (Unigram, Bigram, Trigram)**"
      ],
      "metadata": {
        "id": "xFMg7XoMk3hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "text = \"Natural language processing is amazing\".split()\n",
        "print(list(ngrams(text, 1)), list(ngrams(text, 2)), list(ngrams(text, 3)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYTUfpmLi9qX",
        "outputId": "75fb7e47-dea4-4863-9487-20337ad15942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Natural',), ('language',), ('processing',), ('is',), ('amazing',)] [('Natural', 'language'), ('language', 'processing'), ('processing', 'is'), ('is', 'amazing')] [('Natural', 'language', 'processing'), ('language', 'processing', 'is'), ('processing', 'is', 'amazing')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **N-Gram Smoothing (Add-1 Laplace)**"
      ],
      "metadata": {
        "id": "brFrpQFclBuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "words = \"a a b a b c\".split()\n",
        "freq = Counter(words)\n",
        "print((freq['m'] + 1) / (len(words) + len(freq)))  # P(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbSGVOnIlEu9",
        "outputId": "bef7b038-a933-4b3a-e631-4744b9ab5b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **POS Tagging**"
      ],
      "metadata": {
        "id": "hlTTgGp-lU8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')  # <-- new required file\n",
        "\n",
        "text = nltk.word_tokenize(\"He is playing football\")\n",
        "print(nltk.pos_tag(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa_7HcodlZ6V",
        "outputId": "4b5967d7-6213-472c-90d6-e70ac0b85ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'PRP'), ('is', 'VBZ'), ('playing', 'VBG'), ('football', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hidden Markov Model (Simple POS Example using NLTK)**"
      ],
      "metadata": {
        "id": "ZcBOEK2yl9NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = trainer.train_supervised([([ 'I', 'eat'], ['PRP','VB'])])\n",
        "print(tagger.tag(['I','eat']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QehrK2YvlxMf",
        "outputId": "d1bab04a-0ab3-490d-fc15-4eaeefb34f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'eat'), ('eat', 'eat')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:333: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:335: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:331: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:363: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Brill/Bidirectional POS Tagger (Bending POS Tagger)**"
      ],
      "metadata": {
        "id": "f9Y71yD6mU7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag.brill import brill24\n",
        "from nltk.tag import RegexpTagger, BrillTaggerTrainer\n",
        "basic = RegexpTagger([(r'.*', 'NN')])\n",
        "trainer = BrillTaggerTrainer(basic, brill24())\n",
        "tagger = trainer.train([(['He','runs'],['PRP','VBZ'])])\n",
        "print(tagger.tag(['He','runs']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SHHOjlumZxF",
        "outputId": "bb49ee86-93e5-4d28-a68f-0a92bfbf812e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'NN'), ('runs', 'NN')]\n"
          ]
        }
      ]
    }
  ]
}